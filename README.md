# Spring2024
Repository for the Spring 2024 Computational Social Science Workshop

Time: 9:30 AM to 11:50 PM, Thursdays
Location: 1155 E. 60th Street, Chicago IL 60637; Room 295

Sign up to meet over lunch, dinner, or small group settings with our speakers [**here**](https://docs.google.com/spreadsheets/d/18tySJ3FJ8zT8Sh8JW6SixkFsZCOMSZOqru8kVEzVQwo/edit?usp=sharing)

**Future seminars**: [Nilam Ram](https://profiles.stanford.edu/nilam-ram) (4/18, Stanford Communications, virtual), [Uri Hasson](https://psychology.princeton.edu/people/uri-hasson) (4/25, Princeton Psychology, in-person), [Xuechunzi Bai](https://www.xuechunzibai.com/) (5/2, UChicago CogSci & Psychology, in-person),	[Grant Blank](https://www.oii.ox.ac.uk/people/profiles/grant-blank/) (5/9, Oxford Internet Institute, in-person), and [Jake Hoffman](https://www.microsoft.com/en-us/research/people/jmh/) (5/16, Microsoft Research, in-person)!

**4/11** [Ashton Anderson](https://www.cs.toronto.edu/~ashton/) is an Associate Professor in the Department of Computer Science at the University of Toronto, broadly interested in the intersection of AI, data, and society. He runs the [Computational Social Science Lab](https://csslab.cs.toronto.edu/) at the University of Toronto and has made major advances to large-scale understanding of online communities, polarization, and AI designed to collaborate with humans.

**Generative AI for Human Benefit: Lessons from Chess**. Artificial intelligence is becoming increasingly intelligent, kicking off a Cambrian explosion of AI models filling thousands of niches. Although these tools may replace human effort in some domains, many other areas will foster a combination of human and AI participation. A central challenge in realizing the full potential of human-AI collaboration is that algorithms often act very differently than people, and thus may be uninterpretable, hard to learn from, or even dangerous for humans to follow. For the past six years, my group has been exploring how to align generative AI for human benefit in an ideal model system, chess, in which AI has been superhuman for over two decades, a massive amount of fine-grained data on human actions is available, and a wide spectrum of skill levels exist. We developed Maia, a generative AI model that captures human style and ability in chess across the spectrum of human skill, and predicts likely next human actions analogously to how large language models predict likely next tokens. The Maia project started with these aggregated population models, which have now played millions of games against human opponents online, and has grown to encompass individual models that act like specific people, embedding models that can identify a person by a small sample of their actions alone, an ethical framework for issues that arise with individual models in any domain, various types of partner agents designed from combining human-like and superhuman AI, and algorithmic teaching systems. In this talk, I will share our approaches to designing generative AI for human benefit and the broadly applicable lessons we have learned about human-AI interaction. Paper: ["Designing Skill-Compatible AI: Methodologies and Frameworks in Chess", Karim Hamade, Reid McIlroy-Young, Siddhartha Sen, Jon Kleinberg, and Ashton Anderson.](https://urldefense.com/v3/__https://www.cs.toronto.edu/*ashton/pubs/maia-partner-iclr24.pdf__;fg!!BpyFHLRN4TMTrA!5ggUKNc5qX0BM3wzdSdqoyryrug_ikaRob9TYpuygrh-tiCNwSPtgekQKn8D86xZbcdCn85Ro5otlccayN9yQIw$) in ICLR 2024.

**3/28** [John Wixted](https://psychology.ucsd.edu/people/profiles/jwixted.html), is a Distinguished Professor of Psychology at UCSD with research focused on understanding episodic memory. His work investigates the cognitive mechanisms that underlie recognition memory, often drawing upon signal detection theory. He also investigates how episodic memory is represented in the human hippocampus, based mainly on single-unit recording studies performed with epilepsy patients. In recent years, his research has also investigated the applied implications of signal detection-based models of recognition memory and its implications for the reliability of eyewitness memory.

**Emerging Insights into the Reliability of Eyewitness Memory**. Eyewitness misidentifications have contributed to many wrongful convictions. However, despite expressing high confidence at trial, eyewitnesses often make inconclusive misidentifications on the first test conducted early in a police investigation. According to a new scientific consensus, it is important to focus on the results of the first test because, if the perpetrator is not in the lineup, the test itself leaves a memory trace of the innocent suspect in the witness’s brain. Thus, all subsequent tests of the witness’s memory for the same suspect constitute tests of contaminated memory. Unfortunately, when evidence of an initial inconclusive identification is introduced at trial, the rules of evidence provide a witness with an opportunity to explain their prior inconsistent statement. In response, witnesses often provide an opinion about why they did not confidently identify the suspect on the initial test despite doing so now (e.g., “I was nervous on the first test”). However, witnesses lack expertise in—and have no awareness of—the subconscious mechanisms of memory contamination that have been elucidated by decades of scientific research. The combination of a sincerely held (false) memory and a believable (but erroneous) explanation for a prior inconsistent statement is often persuasive to jurors. This is a recipe for a wrongful conviction, one that has been followed many times. These wrongful convictions, which have long been attributed to the unreliability of eyewitness memory, instead reflect a system that unwittingly prioritizes false memories elicited at trial over true memories elicited early in a police investigation. The Federal Rules of Evidence were enacted almost a half-century ago, and it may be time to revisit them in light of the principles of memory that have been established since that time. Related paper on **The Mechanisms of Memory vs. the Federal Rules of Evidence** sent by email.

Pose your questions [**here!**](https://github.com/uchicago-computation-workshop/Spring2024/issues/1)
